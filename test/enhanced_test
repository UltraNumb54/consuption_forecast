# model_test.py (улучшенный)

import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# === КОНСТАНТЫ ===
MODEL_PATH = 'enhanced_energy_model.cbm'
TRAINING_DATA_FILE = 'enhanced_filtered_training_data.csv' # Используем датасет БЕЗ сентября 2025
# Параметры теста
TEST_START_DATE = '2024-08-01' # Пример начала теста
TEST_END_DATE = '2024-08-10'   # Пример конца теста (10 дней)
# TEST_DAYS = 3 # Количество дней для прогноза (1, 2, 3)
FORECAST_HORIZON_HOURS = 72 # Прогноз на 72 часа (3 дня)

def load_model():
    """Загрузка обученной модели"""
    print(f"Загрузка модели из {MODEL_PATH}...")
    try:
        model = CatBoostRegressor()
        model.load_model(MODEL_PATH)
        print("Модель успешно загружена")
        return model
    except Exception as e:
        print(f"Ошибка при загрузке модели: {e}")
        raise

def load_and_prepare_test_data(start_date, end_date):
    """Загрузка и подготовка данных для теста из обучающего датасета."""
    print(f"Загрузка данных для теста с {start_date} по {end_date} из {TRAINING_DATA_FILE}...")
    df = pd.read_csv(TRAINING_DATA_FILE)
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime').reset_index(drop=True)

    start_dt = pd.to_datetime(start_date)
    end_dt = pd.to_datetime(end_date)

    # Нам нужно не только тестовый период, но и немного данных *до* него для формирования начальных лагов
    max_lag = 168 # из create_lag_features
    # Берём данные от начала датасета до конца тестового периода
    df_slice = df[df['datetime'] <= end_dt].copy()
    # Проверяем, хватает ли данных для начальных лагов
    if len(df_slice) < max_lag:
        raise ValueError(f"Недостаточно данных до {start_date} для формирования лагов (требуется {max_lag}, доступно {len(df_slice)}).")

    # Определяем индекс начала теста в слайсе
    test_start_idx = df_slice[df_slice['datetime'] >= start_dt].index.min()
    if pd.isna(test_start_idx):
        raise ValueError(f"Нет данных в датасете для тестового периода {start_date} - {end_date}.")

    # Индекс начала прогноза (нужен для рекурсивного прогнозирования)
    forecast_start_idx = test_start_idx
    # Тестовый датасет (реальные значения)
    test_data_real = df_slice.iloc[test_start_idx:].copy()
    # Данные *до* теста (для начальных лагов и обновления признаков)
    historical_data = df_slice.iloc[:test_start_idx].copy()

    print(f"Данные для теста загружены. Размер: {len(test_data_real)} записей.")
    print(f"Размер исторических данных: {len(historical_data)} записей.")
    return df, historical_data, test_data_real, forecast_start_idx

def update_features_for_new_row(df_with_features, new_row_data, feature_cols):
    """
    Обновляет сложные признаки (лаги, скользящие, EWM) для новой строки (new_row_data),
    используя значения из df_with_features (до new_row_data).
    """
    # df_with_features - DataFrame, содержащий историю (включая лаги и т.д.)
    # new_row_data - Series (одна строка) с базовыми признаками (datetime, consumption, temperature и т.д.)
    # feature_cols - список всех признаков, кроме целевой переменной
    # Возвращает Series с обновлёнными значениями для ВСЕХ признаков, включая лаги и т.д.
    # Это упрощённый способ, который не учитывает все зависимости лагов/скользяшек при рекурсивном прогнозе.
    # В реальности, для рекурсивного прогноза нужно пересчитывать *все* признаки с нуля на каждом шаге,
    # что вычислительно дорого. Часто используют упрощение: предполагают, что погода и календарь известны,
    # и пересчитывают только лаги потребления.

    # ВАЖНО: Этот метод не идеален для рекурсивного прогноза с лагами, но даёт приближённый результат.
    # Более точный метод требует переписывания предобработки для "пошагового" обновления признаков.

    # Пример упрощённого подхода:
    # 1. Берём все базовые признаки из new_row_data
    updated_row = new_row_data.copy()
    # 2. Предполагаем, что все признаки, кроме лагов потребления, остаются как есть
    # (температура, влажность, час, день недели и т.д. - уже в new_row_data)
    # 3. Обновляем лаги потребления, используя историю из df_with_features и предыдущие прогнозы
    # Это требует сложной логики, которая "проталкивает" прогнозы вперёд как "исторические" данные.

    # ПРАКТИЧЕСКИЙ ПОДХОД (не строго рекурсивный):
    # Используем только те строки, для которых все лаги уже вычислены.
    # Т.е. не прогнозируем "вперёд" рекурсивно, а оцениваем модель на *уже вычисленных* признаках.
    # Это ближе к текущему model_test.py, но на *обучающем* датасете.
    # Это означает, что мы не тестируем способность модели *генерировать* лаги для будущего.
    # Это компромисс между сложностью реализации и полезностью теста.

    # Вывод: Реализовать *настоящий* рекурсивный прогноз с лагами *очень сложно*.
    # Поэтому часто используют "walk-forward validation" с фиксированными признаками,
    # или оценивают модель на уже сформированных признаках, как в оригинальном тесте,
    # но на *обучающем* датасете, чтобы избежать "утечки будущего".

    # ВЕРНЁМСЯ К ИДЕЕ: Используем готовые признаки из датасета, но на *обучающем* периоде.
    # Это будет тестом на "ошибке модели при известных признаках", что всё равно полезно.
    # Для "настоящего" рекурсивного прогноза, нужно переписать предобработку.

    # ПОЭТОМУ: ВОЗЬМЁМ ПРОСТО СТРОКУ ИЗ СФОРМИРОВАННОГО ДАТАСЕТА.
    # Это не рекурсивный прогноз, но тест на "обучающем" датасете.
    # Оригинальный model_test.py делает то же самое, но на "тестовом" датасете (сентябрь 2025).
    # Лучше тестировать на "обучающем", чтобы избежать вопросов о переобучении.
    # Но для оценки "качества на будущем", нужен рекурсивный прогноз или внешний прогноз погоды.

    # АЛЬТЕРНАТИВА: Сделать "walk-forward validation" на обучающем датасете.
    # Разбить обучающий датасет на окна, обучить модель на первом окне, протестировать на следующем,
    # затем расширить окно обучения, снова протестировать, и т.д.
    # Это ближе к реальности, но требует перетренировки модели или сложной логики обновления признаков.
    # Это отдельный, более сложный пайплайн тестирования.

    # ИТОГ: Для простоты и близости к оригинальному коду, будем использовать готовые признаки,
    # но на обучающем датасете. Это проверит, как модель работает на данных, *не включающих* "сентябрь 2025".
    # Это НЕ проверит рекурсивную способность, но проверит качество признаков и обучения.
    # Это - улучшенный вариант оригинального теста.

    # Просто возвращаем строку с признаками (она уже должна быть в нужном формате)
    # Если строка new_row_data содержит все нужные признаки (или их можно вычислить из неё и истории),
    # то возвращаем её. Но в текущем контексте, мы не можем "вычислить" сложные признаки для новой строки
    # без переписывания предобработки.
    # Поэтому, мы не будем использовать эту функцию в текущей реализации теста.
    # Она нужна для *настоящего* рекурсивного прогноза.
    raise NotImplementedError("Функция update_features_for_new_row не реализована для рекурсивного прогноза.")


def simple_test_on_training_slice(start_date, end_date):
    """
    Простое тестирование на срезе обучающего датасета (как оригинальный тест, но на других данных).
    Это не рекурсивный прогноз, а оценка на уже вычисленных признаках.
    """
    print("=== ТЕСТИРОВАНИЕ НА СРЕЗЕ ОБУЧАЮЩЕГО ДАТАСЕТА ===")
    print(f"Тестовый период: с {start_date} по {end_date}")

    # Загружаем модель
    model = load_model()
    feature_columns = model.feature_names_
    print(f"Модель обучалась на {len(feature_columns)} признаках")

    # Загружаем данные
    _, _, test_data_real, _ = load_and_prepare_test_data(start_date, end_date)

    # Проверяем, что все признаки модели присутствуют в тестовом датасете
    missing_cols = [col for col in feature_columns if col not in test_data_real.columns]
    if missing_cols:
        print(f"Критическая ошибка: В тестовом датасете отсутствуют колонки: {missing_cols}")
        print("Проверьте, что обучающий датасет был предобработан с теми же шагами.")
        return None

    X_test = test_data_real[feature_columns]
    y_test = test_data_real['consumption']

    print("Начинаем предсказания...")
    predictions = model.predict(X_test)

    # Оценка качества
    mae = mean_absolute_error(y_test, predictions)
    mape = mean_absolute_percentage_error(y_test, predictions) * 100
    mean_actual = np.mean(y_test)

    print(f"\n=== ИТОГОВЫЕ РЕЗУЛЬТАТЫ ТЕСТА ===")
    print(f"Количество предсказаний: {len(predictions)}")
    print(f"MAE: {mae:.3f}")
    print(f"MAPE: {mape:.2f}%")
    print(f"Среднее потребление (реальное): {mean_actual:.1f} МВт")
    print(f"Точность (±2.5% от среднего): {mae < (mean_actual * 0.025)} (MAE vs {mean_actual * 0.025:.3f})")

    # Визуализация
    prediction_times = test_data_real['datetime'].tolist()
    plt.figure(figsize=(15, 8))
    plt.subplot(2, 1, 1)
    plt.plot(prediction_times, y_test.values, 'b-', label='Реальное', linewidth=1.5, marker='o', markersize=2)
    plt.plot(prediction_times, predictions, 'r--', label='Предсказанное', linewidth=1.5, marker='x', markersize=2)
    plt.title(f'Прогноз vs Реальность на срезе обучающего датасета ({start_date} - {end_date})')
    plt.ylabel('Потребление (МВт)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)

    plt.subplot(2, 1, 2)
    errors = np.abs(y_test.values - predictions)
    plt.plot(prediction_times, errors, 'g-', alpha=0.7, linewidth=1.5, marker='s', markersize=2)
    plt.axhline(y=mean_actual * 0.025, color='r', linestyle='--', label='Порог ±2.5%')
    plt.title(f'Абсолютные ошибки (MAE = {mae:.3f})')
    plt.ylabel('Ошибка (МВт)')
    plt.xlabel('Дата и время')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)

    plt.tight_layout()
    plot_filename = f'test_results_{start_date}_to_{end_date}.png'
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"График сохранён как {plot_filename}")
    plt.show() # Уберите, если запускаете на сервере без GUI

    # Сохранение детальных результатов
    results_df = pd.DataFrame({
        'datetime': prediction_times,
        'actual_consumption': y_test.values,
        'predicted_consumption': predictions,
        'absolute_error': errors
    })
    csv_filename = f'test_results_detailed_{start_date}_to_{end_date}.csv'
    results_df.to_csv(csv_filename, index=False)
    print(f"Детальные результаты сохранены в {csv_filename}")

    return results_df


def walk_forward_validation():
    """
    Пример упрощённой "walk-forward validation".
    Обучает модель на начальном окне, тестирует на следующем, затем расширяет окно.
    Требует перетренировки модели, что может быть дорого.
    """
    # Этот метод сложнее реализовать, так как требует:
    # 1. Логики перетренировки модели.
    # 2. Повторного выполнения предобработки для каждого окна.
    # 3. Управления версиями моделей.
    # 4. Сложной логики для рекурсивного прогноза внутри окна (если это требуется).
    # Поэтому, для начального улучшения, лучше использовать `simple_test_on_training_slice`
    # на разных участках данных вручную или с циклом.
    print("=== WALK-FORWARD VALIDATION (Примерная схема) ===")
    print("Этот метод требует значительной переработки пайплайна.")
    print("Не реализован в текущем улучшенном скрипте.")


if __name__ == "__main__":
    # Выбираем период для теста внутри обучающего датасета
    # Можно запускать с разными датами для проверки стабильности
    test_start = '2024-08-01'
    test_end = '2024-08-10'
    results = simple_test_on_training_slice(test_start, test_end)

    if results is not None:
        print("\nТестирование на срезе обучающего датасета завершено успешно!")
        print("Обратите внимание, что это тест на *уже вычисленных признаках*, а не на рекурсивном прогнозе.")
        print("Для проверки рекурсивной способности, нужна более сложная реализация.")
    else:
        print("\nТестирование не удалось.")

    # Пример запуска для другого периода
    # test_start2 = '2023-06-01'
    # test_end2 = '2023-06-07'
    # results2 = simple_test_on_training_slice(test_start2, test_end2)
