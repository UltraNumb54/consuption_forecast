# model_training_2_years.py
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import make_scorer, mean_absolute_percentage_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# === –ö–û–ù–°–¢–ê–ù–¢–´ ===
FILTERED_DATA_FILE = 'enhanced_filtered_training_data.csv'  # –î–∞—Ç–∞—Å–µ—Ç –∏–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
MODEL_PATH = 'enhanced_energy_model_2_years.cbm'  # –ù–æ–≤–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏
FEATURES_IMPORTANCE_PATH = 'enhanced_features_importance_2_years.png'
TEST_START_YEAR = 2025
TEST_START_MONTH = 9

def mape_scorer(y_true, y_pred):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π scorer –¥–ª—è MAPE"""
    return -mean_absolute_percentage_error(y_true, y_pred)  # GridSearch –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç, –ø–æ—ç—Ç–æ–º—É –º–∏–Ω—É—Å

def prepare_training_data(df):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 2022 –∏ 2024 –≥–æ–¥–∞ –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–æ–º –≤ 2025"""
    print("=== –ü–û–î–ì–û–¢–û–í–ö–ê –û–ë–£–ß–ê–Æ–©–ò–• –î–ê–ù–ù–´–• (—Ç–æ–ª—å–∫–æ 2022 –∏ 2024) ===")
    
    df['year'] = df['datetime'].dt.year
    df['month'] = df['datetime'].dt.month
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ 2022 –∏ 2024 –≥–æ–¥—ã
    df_filtered = df[df['year'].isin([2022, 2024])]
    
    print(f"–î–∞–Ω–Ω—ã–µ –∑–∞ 2022 –≥–æ–¥: {len(df_filtered[df_filtered['year'] == 2022])} –∑–∞–ø–∏—Å–µ–π")
    print(f"–î–∞–Ω–Ω—ã–µ –∑–∞ 2024 –≥–æ–¥: {len(df_filtered[df_filtered['year'] == 2024])} –∑–∞–ø–∏—Å–µ–π")
    print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(df_filtered)}")
    
    return df_filtered

def train_model_with_optimization():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ 2022 –∏ 2024 –≥–æ–¥–∞"""
    print("=== –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ù–ê –î–ê–ù–ù–´–• –ó–ê 2022 –ò 2024 –ì–û–î–´ ===")
    
    df = pd.read_csv(FILTERED_DATA_FILE)
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime')
    
    print(f"–í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ: {len(df)}")
    print(f"–ü–µ—Ä–∏–æ–¥: {df['datetime'].min()} - {df['datetime'].max()}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: —Ç–æ–ª—å–∫–æ 2022 –∏ 2024
    df = prepare_training_data(df)
    
    if len(df) == 0:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        return None, []
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏)
    base_features = [
        'hour', 'hour_sin', 'hour_cos', 'dayofweek', 'month', 'week_of_year',
        'temperature', 'humidity', 'wind_speed',
        'is_holiday', 'is_working_weekend', 'is_regular_weekend', 'is_working_day',
        'is_weekend_or_holiday', 'is_weekend',
        'is_winter', 'is_spring', 'is_summer', 'is_autumn'
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –ª–∞–≥–∏, —Å–∫–æ–ª—å–∑—è—â–∏–µ –∏ EWM –ø—Ä–∏–∑–Ω–∞–∫–∏
    lag_cols = [col for col in df.columns if 'consumption_lag_' in col]
    rolling_cols = [col for col in df.columns if 'consumption_rolling_' in col]
    ewm_cols = [col for col in df.columns if 'consumption_ewm_' in col]
    
    feature_columns = base_features + lag_cols + rolling_cols + ewm_cols
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    missing_cols = [col for col in feature_columns if col not in df.columns]
    if missing_cols:
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Å–ª–µ–¥—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –¥–∞–Ω–Ω—ã—Ö: {missing_cols}")
        feature_columns = [col for col in feature_columns if col in df.columns]
    
    X = df[feature_columns]
    y = df['consumption']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    categorical_features = [
        'hour', 'dayofweek', 'month', 'week_of_year',
        'is_holiday', 'is_working_weekend', 'is_regular_weekend', 'is_working_day',
        'is_weekend_or_holiday', 'is_weekend',
        'is_winter', 'is_spring', 'is_summer', 'is_autumn'
    ]
    categorical_features = [col for col in categorical_features if col in X.columns]
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    tscv = TimeSeriesSplit(n_splits=3)  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
    
    # –°–µ—Ç–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    param_grid = {
        'iterations': [300],          # –£–º–µ–Ω—å—à–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        'learning_rate': [0.05, 0.1],
        'depth': [6],
        'l2_leaf_reg': [3],
        'random_seed': [42]
    }
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = CatBoostRegressor(
        loss_function='MAPE',
        cat_features=categorical_features,
        verbose=False
    )
    
    print("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
    print("–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
    
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        scoring=make_scorer(mape_scorer, greater_is_better=False),
        cv=tscv,
        n_jobs=-1,
        verbose=2
    )
    
    grid_search.fit(X, y)
    
    print(f"üèÜ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")
    print(f"üìà –õ—É—á—à–∏–π MAPE –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: {-grid_search.best_score_:.4f} (–∏–ª–∏ {(-grid_search.best_score_)*100:.2f}%)")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ train/val (80/20) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å early stopping
    split_idx = int(len(X) * 0.8)
    X_train_final = X.iloc[:split_idx]
    y_train_final = y.iloc[:split_idx]
    X_val_final = X.iloc[split_idx:]
    y_val_final = y.iloc[split_idx:]
    
    # –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
    print("üöÄ –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...")
    best_model = CatBoostRegressor(
        **grid_search.best_params_,
        loss_function='MAPE',
        eval_metric='MAPE',
        cat_features=categorical_features,
        early_stopping_rounds=30,
        use_best_model=True,
        verbose=50
    )
    
    best_model.fit(
        X_train_final, y_train_final,
        eval_set=(X_val_final, y_val_final)
    )
    
    # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (–¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
    y_pred_full = best_model.predict(X)
    mae_full = mean_absolute_error(y, y_pred_full)
    mape_full = mean_absolute_percentage_error(y, y_pred_full) * 100
    
    print(f"üìä –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ–º –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ (2022 –∏ 2024):")
    print(f"   MAE: {mae_full:.3f}")
    print(f"   MAPE: {mape_full:.2f}%")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    y_pred_train = best_model.predict(X_train_final)
    y_pred_val = best_model.predict(X_val_final)
    mae_train = mean_absolute_error(y_train_final, y_pred_train)
    mae_val = mean_absolute_error(y_val_final, y_pred_val)
    overfitting_ratio = mae_val / mae_train if mae_train > 0 else float('inf')
    print(f"‚ö†Ô∏è  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (MAE val / MAE train): {overfitting_ratio:.2f}")
    
    # –í—ã–≤–æ–¥ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print(f"=== –¢–û–ü-15 –°–ê–ú–´–• –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í ===")
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.get_feature_importance()
    }).sort_values('importance', ascending=False)
    
    for i, row in feature_importance.head(15).iterrows():
        print(f"{i+1:2d}. {row['feature']:<30} : {row['importance']:>8.2f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    best_model.save_model(MODEL_PATH)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö 2022 –∏ 2024 –≥–æ–¥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(10, 8))
        top_features = feature_importance.head(15)
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
        plt.title('–¢–æ–ø-15 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–û–±—É—á–µ–Ω–∏–µ –Ω–∞ 2022 –∏ 2024)')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.savefig(FEATURES_IMPORTANCE_PATH, dpi=300, bbox_inches='tight')
        print(f"üìä –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {FEATURES_IMPORTANCE_PATH}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
    
    return best_model, feature_columns

if __name__ == "__main__":
    model, features = train_model_with_optimization()
    if model is not None:
        print("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é.")
    else:
        print("‚ùå –û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å.")
