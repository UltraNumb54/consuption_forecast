import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error

# === –£–õ–£–ß–®–ï–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï ===

def proper_time_series_training():
    """–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    
    print("=== –£–õ–£–ß–®–ï–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï ===")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv('filtered_training_data.csv')
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime')
    
    print(f"–í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {len(df)}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
    numerical_features = [
        'hour', 'dayofweek', 'month',
        'temperature', 'humidity', 'wind_speed',
        'consumption_lag_1', 'consumption_lag_2', 'consumption_lag_3',
        'consumption_lag_24', 'consumption_lag_48', 'consumption_lag_168',
        'consumption_rolling_mean_3', 'consumption_rolling_mean_6',
        'consumption_rolling_mean_12', 'consumption_rolling_mean_24',
        'consumption_rolling_std_3', 'consumption_rolling_std_6',
        'consumption_rolling_std_12', 'consumption_rolling_std_24'
    ]
    
    categorical_features = [
        'is_holiday', 'is_working_weekend', 'is_regular_weekend',
        'is_working_day', 'is_weekend_or_holiday', 'is_weekend'
    ]
    
    feature_columns = numerical_features + categorical_features
    target_column = 'consumption'
    
    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
    df_clean = df[feature_columns + [target_column]].dropna()
    
    X = df_clean[feature_columns]
    y = df_clean[target_column]
    
    print(f"–î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(X)}")
    
    # === –ü–†–ê–í–ò–õ–¨–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê TRAIN/TEST ===
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20% –∫–∞–∫ —Ç–µ—Å—Ç (–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å!)
    split_point = int(len(X) * 0.8)
    
    X_train = X.iloc[:split_point]
    X_test = X.iloc[split_point:]
    y_train = y.iloc[:split_point]
    y_test = y.iloc[split_point:]
    
    print(f"Train: {len(X_train)} –∑–∞–ø–∏—Å–µ–π")
    print(f"Test: {len(X_test)} –∑–∞–ø–∏—Å–µ–π")
    print(f"–ü–µ—Ä–∏–æ–¥ —Ç–µ—Å—Ç–∞: {df.iloc[split_point]['datetime']} - {df.iloc[-1]['datetime']}")
    
    # === –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ú–û–î–ï–õ–¨ ===
    model = CatBoostRegressor(
        iterations=500,  # –ú–µ–Ω—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        learning_rate=0.05,  # –ú–µ–Ω—å—à–µ learning rate
        depth=4,  # –ú–µ–Ω—å—à–µ –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤
        l2_leaf_reg=3,  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
        loss_function='MAE',
        eval_metric='MAE',
        random_seed=42,
        verbose=50,
        early_stopping_rounds=30,
        task_type='CPU'
    )
    
    print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    model.fit(
        X_train, y_train,
        cat_features=categorical_features,
        eval_set=(X_test, y_test),
        use_best_model=True
    )
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # –û—Ü–µ–Ω–∫–∞
    mae_train = mean_absolute_error(y_train, y_pred_train)
    mae_test = mean_absolute_error(y_test, y_pred_test)
    mape_test = mean_absolute_percentage_error(y_test, y_pred_test) * 100
    
    print(f"\n=== –£–õ–£–ß–®–ï–ù–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===")
    print(f"MAE –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {mae_train:.3f}")
    print(f"MAE –Ω–∞ —Ç–µ—Å—Ç–µ: {mae_test:.3f}")
    print(f"MAPE –Ω–∞ —Ç–µ—Å—Ç–µ: {mape_test:.2f}%")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ: {y_test.mean():.1f}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å (¬±2.5%): {mae_test < (y_test.mean() * 0.025)}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model.save_model('improved_energy_model.cbm')
    print("–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
    
    return model

def cross_validate_time_series():
    """–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    print("\n=== –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø –í–†–ï–ú–ï–ù–ù–´–• –†–Ø–î–û–í ===")
    
    df = pd.read_csv('filtered_training_data.csv')
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime')
    
    # TimeSeriesSplit –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    tscv = TimeSeriesSplit(n_splits=5)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    numerical_features = [
        'hour', 'dayofweek', 'month',
        'temperature', 'humidity', 'wind_speed',
        'consumption_lag_1', 'consumption_lag_2', 'consumption_lag_3',
        'consumption_lag_24', 'consumption_lag_48', 'consumption_lag_168',
        'consumption_rolling_mean_3', 'consumption_rolling_mean_6',
        'consumption_rolling_mean_12', 'consumption_rolling_mean_24',
        'consumption_rolling_std_3', 'consumption_rolling_std_6',
        'consumption_rolling_std_12', 'consumption_rolling_std_24'
    ]
    
    categorical_features = [
        'is_holiday', 'is_working_weekend', 'is_regular_weekend',
        'is_working_day', 'is_weekend_or_holiday', 'is_weekend'
    ]
    
    feature_columns = numerical_features + categorical_features
    target_column = 'consumption'
    
    df_clean = df[feature_columns + [target_column]].dropna()
    X = df_clean[feature_columns]
    y = df_clean[target_column]
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    mae_scores = []
    
    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
        print(f"Fold {fold + 1}/5")
        
        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
        
        model = CatBoostRegressor(
            iterations=300,
            learning_rate=0.05,
            depth=4,
            l2_leaf_reg=3,
            loss_function='MAE',
            eval_metric='MAE',
            random_seed=42,
            verbose=0
        )
        
        model.fit(
            X_train_fold, y_train_fold,
            cat_features=categorical_features,
            eval_set=(X_val_fold, y_val_fold),
            use_best_model=True,
            early_stopping_rounds=20
        )
        
        y_pred = model.predict(X_val_fold)
        mae = mean_absolute_error(y_val_fold, y_pred)
        mae_scores.append(mae)
        print(f"  MAE: {mae:.3f}")
    
    print(f"\n–°—Ä–µ–¥–Ω–∏–π MAE –ø–æ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: {np.mean(mae_scores):.3f} ¬± {np.std(mae_scores):.3f}")
    
    return mae_scores

def analyze_model_performance():
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    print("\n" + "="*60)
    print("–ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú –° –ú–û–î–ï–õ–¨–Æ")
    print("="*60)
    
    print("""
    üéØ –ü–†–û–ë–õ–ï–ú–ê: –†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É train/test –∏ —Ä–µ–∞–ª—å–Ω—ã–º —Ç–µ—Å—Ç–æ–º
    
    –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:
    
    1Ô∏è‚É£ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï:
       ‚Ä¢ –ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è
       ‚Ä¢ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
       ‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    
    2Ô∏è‚É£ –£–¢–ï–ß–ö–ê –î–ê–ù–ù–´–•:
       ‚Ä¢ –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±—É–¥—É—â–µ–≥–æ
       ‚Ä¢ –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
       ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –ø—Ä–∏ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏
    
    3Ô∏è‚É£ –†–ê–ó–ù–´–ï –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø:
       ‚Ä¢ –°–µ–Ω—Ç—è–±—Ä—å 2025 –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –¥—Ä—É–≥–∏—Ö –º–µ—Å—è—Ü–µ–≤
       ‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞ —Å–µ–Ω—Ç—è–±—Ä—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
       ‚Ä¢ –°–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
    
    4Ô∏è‚É£ –ü–†–û–ë–õ–ï–ú–´ –° –ü–û–ì–û–î–û–ô:
       ‚Ä¢ –ü–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–µ—Å—Ç–µ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –æ–±—É—á–∞—é—â–∏—Ö
       ‚Ä¢ –û—à–∏–±–∫–∏ –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ –ø–æ–≥–æ–¥—ã —Å–∏–ª—å–Ω–æ –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    
    üîß –†–ï–®–ï–ù–ò–Ø:
    
    1. –£–º–µ–Ω—å—à–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    4. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    """)

if __name__ == "__main__":
    analyze_model_performance()
    
    # –ü–æ–ø—Ä–æ–±—É–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    try:
        model = proper_time_series_training()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: {e}")
    
    # –ü–æ–ø—Ä–æ–±—É–µ–º –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
    try:
        scores = cross_validate_time_series()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")


  # consumption_rolling_mean_3 - —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —á–∞—Å–∞
# –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç—Ä–µ–Ω–¥: —Ä–∞—Å—Ç–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –∏–ª–∏ –ø–∞–¥–∞–µ—Ç

# consumption_lag_1 - –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ 1 —á–∞—Å –Ω–∞–∑–∞–¥  
# –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: –µ—Å–ª–∏ —Å–µ–π—á–∞—Å 1200 –ú–í—Ç, —Ç–æ —á–µ—Ä–µ–∑ —á–∞—Å ~1200 –ú–í—Ç

# consumption_lag_24 - –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ 24 —á–∞—Å–∞ –Ω–∞–∑–∞–¥
# –°—É—Ç–æ—á–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å: —É—Ç—Ä–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ —É—Ç—Ä–æ

# consumption_lag_168 - –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –Ω–µ–¥–µ–ª—é –Ω–∞–∑–∞–¥  
# –ù–µ–¥–µ–ª—å–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å: –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –ø–æ—Ö–æ–∂ –Ω–∞ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫

