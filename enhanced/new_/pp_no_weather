1. optimized_preprocessing_no_weather.py
python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# === –ö–û–ù–°–¢–ê–ù–¢–´ ===
CONSUMPTION_FILE = 'consumption_data.csv'
CALENDAR_FILE = 'russian_production_calendar_2017_2025.csv'
OUTPUT_FILE = 'optimized_processed_energy_data_no_weather.csv'

def preprocess_consumption_data():
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏–∑ consumption"""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—é...")
    try:
        df_consumption = pd.read_csv(CONSUMPTION_FILE, sep=';', parse_dates=['date'])
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {CONSUMPTION_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    df_consumption['datetime'] = pd.to_datetime(df_consumption['date']) + pd.to_timedelta(df_consumption['hour'], unit='h')
    df_consumption = df_consumption.dropna(subset=['consumption', 'temperature'])
    
    # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    columns_to_drop = ['temperature_forecast', 'week_day']
    df_consumption = df_consumption.drop(columns=[col for col in columns_to_drop if col in df_consumption.columns])
    
    # –ë–∞–∑–æ–≤—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_consumption['hour'] = df_consumption['datetime'].dt.hour
    df_consumption['dayofweek'] = df_consumption['datetime'].dt.dayofweek
    df_consumption['month'] = df_consumption['datetime'].dt.month
    df_consumption['year'] = df_consumption['datetime'].dt.year
    df_consumption['dayofyear'] = df_consumption['datetime'].dt.dayofyear
    
    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —á–∞—Å–∞
    df_consumption['hour_sin'] = np.sin(2 * np.pi * df_consumption['hour'] / 24)
    df_consumption['hour_cos'] = np.cos(2 * np.pi * df_consumption['hour'] / 24)
    
    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–µ—Å—è—Ü–∞
    df_consumption['month_sin'] = np.sin(2 * np.pi * df_consumption['month'] / 12)
    df_consumption['month_cos'] = np.cos(2 * np.pi * df_consumption['month'] / 12)
    
    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –¥–Ω—è –≥–æ–¥–∞
    df_consumption['dayofyear_sin'] = np.sin(2 * np.pi * df_consumption['dayofyear'] / 365)
    df_consumption['dayofyear_cos'] = np.cos(2 * np.pi * df_consumption['dayofyear'] / 365)
    
    # –°–µ–∑–æ–Ω (1-4)
    df_consumption['season'] = df_consumption['month'] % 12 // 3 + 1
    
    # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–æ–ª—å–∫–æ –∏–∑ consumption)
    df_consumption['temp_squared'] = df_consumption['temperature'] ** 2
    df_consumption['temp_cubed'] = df_consumption['temperature'] ** 3
    
    # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–µ –∑–æ–Ω—ã (–æ—á–µ–Ω—å —Ö–æ–ª–æ–¥–Ω–æ, —Ö–æ–ª–æ–¥–Ω–æ, –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ, —Ç–µ–ø–ª–æ, –∂–∞—Ä–∫–æ)
    df_consumption['temp_zone'] = pd.cut(df_consumption['temperature'], 
                                       bins=[-40, -10, 0, 10, 20, 30, 40],
                                       labels=['very_cold', 'cold', 'cool', 'comfort', 'warm', 'hot'])
    
    print(f"–î–∞–Ω–Ω—ã–µ –ø–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –†–∞–∑–º–µ—Ä: {len(df_consumption)}")
    return df_consumption

def load_calendar():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–µ–Ω–¥–∞—Ä—è"""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è...")
    try:
        df_calendar = pd.read_csv(CALENDAR_FILE)
        df_calendar['date'] = pd.to_datetime(df_calendar['date']).dt.date
        return df_calendar
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {CALENDAR_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None

def create_temporal_features(df):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    df = df.sort_values('datetime')
    
    # –õ–∞–≥–∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
    important_lags = [1, 2, 3, 4, 5, 6, 24, 48, 72, 168]  # –î–æ–±–∞–≤–∏–ª–∏ –±–æ–ª—å—à–µ –ª–∞–≥–æ–≤
    for lag in important_lags:
        df[f'consumption_lag_{lag}'] = df['consumption'].shift(lag)
    
    # –õ–∞–≥–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    temp_lags = [1, 24, 48]
    for lag in temp_lags:
        df[f'temperature_lag_{lag}'] = df['temperature'].shift(lag)
    
    # –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
    windows = [3, 6, 12, 24, 48, 168]  # –î–æ–±–∞–≤–∏–ª–∏ –±–æ–ª—å—à–µ –æ–∫–æ–Ω
    for window in windows:
        df[f'consumption_rolling_mean_{window}'] = df['consumption'].rolling(window=window, min_periods=1).mean()
        df[f'consumption_rolling_std_{window}'] = df['consumption'].rolling(window=window, min_periods=1).std()
    
    # –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    temp_windows = [24, 168]
    for window in temp_windows:
        df[f'temperature_rolling_mean_{window}'] = df['temperature'].rolling(window=window, min_periods=1).mean()
    
    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
    df['consumption_ewm_24'] = df['consumption'].ewm(span=24).mean()
    df['consumption_ewm_168'] = df['consumption'].ewm(span=168).mean()
    
    # –†–∞–∑–Ω–æ—Å—Ç–∏ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ)
    df['consumption_diff_1'] = df['consumption'].diff(1)
    df['consumption_diff_24'] = df['consumption'].diff(24)
    
    # –°—É—Ç–æ—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–æ —á–∞—Å—É –¥–Ω—è)
    hourly_patterns = df.groupby('hour')['consumption'].mean().to_dict()
    df['hourly_pattern'] = df['hour'].map(hourly_patterns)
    
    # –ù–µ–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–æ –¥–Ω—é –Ω–µ–¥–µ–ª–∏)
    weekday_patterns = df.groupby('dayofweek')['consumption'].mean().to_dict()
    df['weekday_pattern'] = df['dayofweek'].map(weekday_patterns)
    
    return df

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–µ–∑ –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("=== –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –ë–ï–ó –ü–û–ì–û–î–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í ===")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_consumption = preprocess_consumption_data()
    df_calendar = load_calendar()
    
    if df_consumption is None or df_calendar is None:
        return

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—å
    df_consumption['date_only'] = df_consumption['datetime'].dt.date
    df_calendar['date_for_merge'] = pd.to_datetime(df_calendar['date']).dt.date
    df_final = pd.merge(df_consumption, df_calendar, left_on='date_only', right_on='date_for_merge', how='left')

    # –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_final['is_weekend'] = (df_final['day_type'] == 'weekend').astype(int)
    df_final['is_holiday'] = (df_final['day_type'] == 'non-working holiday').astype(int)
    df_final['is_working_day'] = (df_final['day_type'] == 'working day').astype(int)
    df_final['is_working_weekend'] = (df_final['day_type'] == 'working weekend').astype(int)

    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_final = create_temporal_features(df_final)

    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    initial_size = len(df_final)
    df_final = df_final.dropna()
    final_size = len(df_final)
    print(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {initial_size - final_size}")

    # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    columns_to_drop = ['date_only', 'date_for_merge', 'day_type', 'date']
    df_final = df_final.drop(columns=[col for col in columns_to_drop if col in df_final.columns])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    df_final.to_csv(OUTPUT_FILE, index=False)
    print(f"=== –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –ë–ï–ó –ü–û–ì–û–î–ù–´–• –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù–ê ===")
    print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(df_final)} —Å—Ç—Ä–æ–∫, {len(df_final.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n–§–ò–ù–ê–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò (–±–µ–∑ –≤–Ω–µ—à–Ω–µ–π –ø–æ–≥–æ–¥—ã):")
    features = [col for col in df_final.columns if col not in ['datetime', 'consumption']]
    for i, col in enumerate(sorted(features)):
        print(f"{i+1:2d}. {col}")

if __name__ == "__main__":
    main()
2. optimized_training_no_weather.py
python
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import make_scorer, mean_absolute_percentage_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# === –ö–û–ù–°–¢–ê–ù–¢–´ ===
OPTIMIZED_DATA_FILE = 'optimized_processed_energy_data_no_weather.csv'
MODEL_PATH = 'optimized_energy_model_no_weather.cbm'

def mape_scorer(y_true, y_pred):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π scorer –¥–ª—è MAPE"""
    return -mean_absolute_percentage_error(y_true, y_pred)

def get_optimized_features_no_weather(df):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ë–ï–ó –≤–Ω–µ—à–Ω–∏—Ö –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    # –û–°–ù–û–í–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò (—Ç–æ–ª—å–∫–æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑ consumption)
    core_features = [
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
        'consumption_lag_1', 'consumption_lag_2', 'consumption_lag_3', 
        'consumption_lag_24', 'consumption_lag_48', 'consumption_lag_168',
        'consumption_rolling_mean_24', 'consumption_rolling_mean_168',
        'consumption_ewm_24', 'consumption_ewm_168',
        'consumption_diff_1', 'consumption_diff_24',
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        'hourly_pattern', 'weekday_pattern',
        
        # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–æ–ª—å–∫–æ –∏–∑ consumption)
        'temperature', 'temp_squared', 'temp_cubed',
        'temperature_lag_1', 'temperature_lag_24',
        'temperature_rolling_mean_24', 'temperature_rolling_mean_168',
        
        # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        'hour_sin', 'hour_cos', 'month_sin', 'month_cos',
        'dayofyear_sin', 'dayofyear_cos',
        
        # –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        'is_weekend', 'is_holiday', 'is_working_day', 'is_working_weekend',
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        'year', 'season', 'hour', 'month', 'dayofweek', 'dayofyear',
        'temp_zone'
    ]
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    existing_features = [feature for feature in core_features if feature in df.columns]
    
    print("–ü–†–ò–ó–ù–ê–ö–ò –ë–ï–ó –í–ù–ï–®–ù–ï–ô –ü–û–ì–û–î–´:")
    for i, feature in enumerate(existing_features):
        print(f"{i+1:2d}. {feature}")
    
    return existing_features

def train_optimized_model_no_weather():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ë–ï–ó –≤–Ω–µ—à–Ω–∏—Ö –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("=== –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ë–ï–ó –í–ù–ï–®–ù–ò–• –ü–û–ì–û–î–ù–´–• –î–ê–ù–ù–´–• ===")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv(OPTIMIZED_DATA_FILE)
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime')

    print(f"–î–∞–Ω–Ω—ã–µ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    print(f"–ü–µ—Ä–∏–æ–¥: {df['datetime'].min()} - {df['datetime'].max()}")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –±–µ–∑ –≤–Ω–µ—à–Ω–µ–π –ø–æ–≥–æ–¥—ã
    feature_columns = get_optimized_features_no_weather(df)
    
    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    target_column = 'consumption'
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º X –∏ y
    X = df[feature_columns]
    y = df[target_column]
    
    print(f"X shape: {X.shape}, y shape: {y.shape}")

    # –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
    categorical_features = [
        'season', 'is_weekend', 'is_holiday', 'is_working_day', 'is_working_weekend',
        'year', 'month', 'dayofweek', 'hour', 'temp_zone'
    ]
    categorical_features = [col for col in categorical_features if col in feature_columns]
    
    print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {categorical_features}")

    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    tscv = TimeSeriesSplit(n_splits=3)

    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Ç–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    param_grid = {
        'iterations': [300, 500],
        'learning_rate': [0.05, 0.1],
        'depth': [6, 8],
        'l2_leaf_reg': [3, 5],
        'random_seed': [42]
    }

    # –ú–æ–¥–µ–ª—å
    model = CatBoostRegressor(
        loss_function='MAPE',
        cat_features=categorical_features,
        verbose=False
    )

    # –ü–æ–∏—Å–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    print("\nüîç –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        scoring=make_scorer(mape_scorer, greater_is_better=False),
        cv=tscv,
        n_jobs=-1,
        verbose=1
    )

    grid_search.fit(X, y)

    print(f"\nüèÜ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")
    print(f"üìà –õ—É—á—à–∏–π MAPE: {-grid_search.best_score_:.4f}")

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å early stopping
    split_idx = int(len(X) * 0.8)
    X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]

    print("\nüöÄ –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ...")
    best_model = CatBoostRegressor(
        **grid_search.best_params_,
        loss_function='MAPE',
        eval_metric='MAPE',
        cat_features=categorical_features,
        early_stopping_rounds=20,
        use_best_model=True,
        verbose=50
    )

    best_model.fit(X_train, y_train, eval_set=(X_val, y_val))

    # –û—Ü–µ–Ω–∫–∞
    y_pred = best_model.predict(X)
    mae = mean_absolute_error(y, y_pred)
    mape = mean_absolute_percentage_error(y, y_pred) * 100
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   MAE: {mae:.3f}")
    print(f"   MAPE: {mape:.2f}%")

    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print(f"\n=== –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í (–±–µ–∑ –≤–Ω–µ—à–Ω–µ–π –ø–æ–≥–æ–¥—ã) ===")
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.get_feature_importance()
    }).sort_values('importance', ascending=False)
    
    for i, row in feature_importance.iterrows():
        print(f"{i+1:2d}. {row['feature']:<30} : {row['importance']:>8.2f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    best_model.save_model(MODEL_PATH)
    print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")

    return best_model, feature_columns

if __name__ == "__main__":
    model, features = train_optimized_model_no_weather()
    print("\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
3. optimized_test_no_weather.py
python
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from datetime import datetime, timedelta

# === –ö–û–ù–°–¢–ê–ù–¢–´ ===
MODEL_PATH = 'optimized_energy_model_no_weather.cbm'
OPTIMIZED_DATA_FILE = 'optimized_processed_energy_data_no_weather.csv'
TEST_START_DATE = '2025-09-01'
TEST_DAYS = 3

def test_optimized_model_no_weather():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ë–ï–ó –≤–Ω–µ—à–Ω–∏—Ö –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("=== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –ë–ï–ó –í–ù–ï–®–ù–ò–• –ü–û–ì–û–î–ù–´–• –î–ê–ù–ù–´–• ===")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = CatBoostRegressor()
    model.load_model(MODEL_PATH)
    feature_columns = model.feature_names_
    print(f"–ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç {len(feature_columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv(OPTIMIZED_DATA_FILE)
    df['datetime'] = pd.to_datetime(df['datetime'])
    print(f"–î–∞–Ω–Ω—ã–µ: {len(df)} –∑–∞–ø–∏—Å–µ–π")

    # –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥
    test_start = datetime.strptime(TEST_START_DATE, '%Y-%m-%d')
    test_end = test_start + timedelta(days=TEST_DAYS)
    test_data = df[(df['datetime'] >= test_start) & (df['datetime'] < test_end)]
    
    if len(test_data) == 0:
        print("–û—à–∏–±–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∞!")
        return

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    X_test = test_data[feature_columns]
    y_test = test_data['consumption']
    predictions = model.predict(X_test)

    # –û—Ü–µ–Ω–∫–∞
    mae = mean_absolute_error(y_test, predictions)
    mape = mean_absolute_percentage_error(y_test, predictions) * 100
    mean_actual = np.mean(y_test)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê (–±–µ–∑ –≤–Ω–µ—à–Ω–µ–π –ø–æ–≥–æ–¥—ã):")
    print(f"–ü–µ—Ä–∏–æ–¥: {test_start} - {test_end}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {len(predictions)}")
    print(f"MAE: {mae:.3f}")
    print(f"MAPE: {mape:.2f}%")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ: {mean_actual:.1f}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å (¬±2.5%): {'–î–ê' if mape < 2.5 else '–ù–ï–¢'}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(12, 8))
    plt.plot(test_data['datetime'], y_test, 'b-', label='–†–µ–∞–ª—å–Ω–æ–µ', linewidth=2)
    plt.plot(test_data['datetime'], predictions, 'r--', label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ', linewidth=2)
    plt.title(f'–ü—Ä–æ–≥–Ω–æ–∑ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –Ω–∞ {TEST_DAYS} –¥–Ω—è (–±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)')
    plt.ylabel('–ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ (–ú–í—Ç)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('optimized_test_results_no_weather.png', dpi=300, bbox_inches='tight')
    plt.show()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_df = pd.DataFrame({
        'datetime': test_data['datetime'],
        'actual': y_test.values,
        'predicted': predictions,
        'error': np.abs(y_test.values - predictions)
    })
    results_df.to_csv('optimized_test_results_no_weather.csv', index=False)
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ optimized_test_results_no_weather.csv")

if __name__ == "__main__":
    test_optimized_model_no_weather()
